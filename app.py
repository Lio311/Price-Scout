import streamlit as st
import pandas as pd
import re
import time
from bs4 import BeautifulSoup

# --- ×™×™×‘×•× Selenium ---
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, WebDriverException

# --- 1. × ×ª×•× ×™ ×§×•× ×¤×™×’×•×¨×¦×™×” ---

# × ×ª×•× ×™ ×§×œ×˜ (××•×ª×’×™×)
BRANDS_TO_MONITOR = ["Amouage", "Xerjoff"]

# ×›×ª×•×‘×•×ª ×”××ª×¨×™× ×©×œ ×”××ª×—×¨×™×
COMPETITORS = {
    "KSP": "https://ksp.co.il/",
    "Kol_B_Yehuda": "https://kolboyehuda.co.il/",
}

# ×”×’×“×¨×ª ×¡×£ ×”×”×ª×¨××” (20% ×›×¤×™ ×©×‘×™×§×©×ª)
PRICE_GAP_THRESHOLD = 0.20 

# × ×ª×•× ×™ ×”××œ××™ ×©×œ×š (×“×•×’××”/Mock Data).
MY_INVENTORY = {
    "Amouage Interlude Man 100ml": 1200,
    "Amouage Reflection Man 100ml": 1100,
    "Xerjoff Naxos 100ml": 1300,
    "Xerjoff Erba Pura 105ml": 1050, # ×©×™× ×™×ª×™ ×œ-105 ×"×œ ×›×“×™ ×œ×”×“×’×™× ×”×ª×××” ×—×œ×§×™×ª
}

# --- 2. × ×™×”×•×œ ×”-WebDriver (×—×™×™×‘ ×œ×”×™×©××¨ ×œ××¢×œ×”) ---

@st.cache_resource
def get_chrome_driver():
    """××’×“×™×¨ ×•××—×–×™×¨ ××ª ×× ×”×œ ×”×“×¤×“×¤×Ÿ ×©×œ ×¡×œ× ×™×•×."""
    
    chrome_options = Options()
    
    # ×”×¤×¢×œ×” ×‘××¦×‘ Headless (×œ×œ× ×××©×§ ×’×¨×¤×™)
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    
    # ×”×¡×•×•××”: ×”×¡×¨×ª ×“×’×œ×™× ×©××–×”×™× ××ª ×¡×œ× ×™×•×
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # User-Agent ×—×“×© ×›×“×™ ×œ×”×™×¨××•×ª ×™×•×ª×¨ ×›××• ×“×¤×“×¤×Ÿ ×¨×’×™×œ
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    chrome_options.add_argument(f'user-agent={user_agent}')

    # ×˜×™×¤×•×œ ×‘×”×ª×§× ×ª ×”×“×¨×™×™×‘×¨
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(30)
        return driver
    except WebDriverException as e:
        # ×”×•×“×¢×ª ×©×’×™××” ×‘×¨×•×¨×” ×× ××™×Ÿ ××¤×©×¨×•×ª ×œ×”×¤×¢×™×œ ××ª ×”×“×¨×™×™×‘×¨
        st.error(f"âŒ ×©×’×™××” ×—××•×¨×”: ×œ× × ×™×ª×Ÿ ×œ×”×¤×¢×™×œ ××ª ×”-Chrome Driver. ×•×“× ×©-Chrome ××•×ª×§×Ÿ.")
        st.stop()
    return None

try:
    # ×˜×¢×™× ×ª ×”×“×¨×™×™×‘×¨ ×¤×¢× ××—×ª ×‘×œ×‘×“
    DRIVER = get_chrome_driver()
except Exception:
    DRIVER = None
    
# --- 3. ×¤×•× ×§×¦×™×•×ª Scraping ××•×ª×××•×ª ××™×©×™×ª ---

def search_and_scrape_ksp(query):
    """
    ××‘×¦×¢ ×—×™×¤×•×© ×‘-KSP ×‘×××¦×¢×•×ª Selenium.
    """
    if not DRIVER:
        return None

    # ×™×¦×™×¨×ª URL ×œ×—×™×¤×•×©
    search_query = query.replace(' ', '+')
    search_url = f"{COMPETITORS['KSP']}web/search/index.aspx?search={search_query}"
    
    try:
        DRIVER.get(search_url)
        
        # ×”××ª× ×” (×¢×“ 10 ×©× ×™×•×ª) ×©×”××—×™×¨ ×™×•×¤×™×¢ ×‘×“×£
        WebDriverWait(DRIVER, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "ProductCardPrice"))
        )
        
        # ×©×™××•×© ×‘-BeautifulSoup ×¢×œ ×”×ª×•×›×Ÿ ×©-Selenium ×˜×¢×Ÿ
        soup = BeautifulSoup(DRIVER.page_source, 'html.parser')
        
        # âš ï¸ ×”×¡×œ×§×˜×•×¨ ×©× ×‘×“×§ ×‘-KSP ×”×•×: div.ProductCardPrice span.price-label-text
        price_tag = soup.select_one('div.ProductCardPrice span.price-label-text') 
        
        if price_tag:
            # ×× ×§×” ×•×××™×¨ ×œ××¡×¤×¨ (××¡×™×¨ ×©×§×œ×™×, ×¤×¡×™×§×™× ×•×›×“')
            price_text = price_tag.text.strip()
            # ××©×ª××© ×‘-Regex ×›×“×™ ×œ××¦×•× ×¨×§ ××¡×¤×¨×™×
            clean_price = re.sub(r'[^\d]', '', price_text) 
            return int(clean_price) if clean_price else None
        
        return None 
        
    except TimeoutException:
        # ×× ×¢×‘×¨ ×–××Ÿ ×”×”××ª× ×”, ×¡×™××Ÿ ×©×”××—×™×¨ ×œ× ×”×•×¤×™×¢ ××• ×©×”××ª×¨ ×—×¡×
        st.warning(f"â³ KSP: ×¤×¡×§ ×–××Ÿ ×¢×‘×•×¨ {query}. ×”××•×¦×¨ ×œ× × ××¦× ××• × ×—×¡×.")
        return None
    
    except Exception as e:
        # ×©×’×™××•×ª ×›×œ×œ×™×•×ª ××—×¨×•×ª (×›××• ×©×’×™××ª ×“×¨×™×™×‘×¨ ××• × ×™×ª×•×§ ×¨×©×ª)
        st.warning(f"âŒ ×©×’×™××ª Scraping ×‘-KSP ×¢×‘×•×¨ {query}: {e}")
        return None


def search_and_scrape_kolboyehuda(query):
    """
    ××‘×¦×¢ ×—×™×¤×•×© ×‘-Kol_B_Yehuda (×“×•×¨×© Selenium).
    """
    if not DRIVER:
        return None
    
    # Kol B'Yehuda ×“×•×¨×© ×’× ×”×•× × ×™×•×•×˜ ×“×¨×š ×—×™×¤×•×©
    # ×”-URL ×”×•× ×¤×©×•×˜, ××‘×œ × ×“×¨×©×ª ×œ×•×’×™×§×” ××•×¨×›×‘×ª ×œ-Scraping.
    search_url = f"https://kolboyehuda.co.il/?s={query.replace(' ', '+')}"
    
    try:
        DRIVER.get(search_url)
        # ×”××ª× ×” ×œ×˜×¢×™× ×ª ×“×£ ×”×ª×•×¦××•×ª
        WebDriverWait(DRIVER, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".product-item"))
        )
        
        soup = BeautifulSoup(DRIVER.page_source, 'html.parser')
        
        # âš ï¸ ×”×¡×œ×§×˜×•×¨ ×©× ×‘×“×§ ×‘××ª×¨ ×–×”: .price-wrapper span.price span.amount
        # ×× ×¡×™× ×œ××¦×•× ××ª ×”××—×™×¨ ×©×œ ×”××•×¦×¨ ×”×¨××©×•×Ÿ
        price_tag = soup.select_one('.product-item .price-wrapper span.amount')

        if price_tag:
            price_text = price_tag.text.strip()
            clean_price = re.sub(r'[^\d]', '', price_text)
            return int(clean_price) if clean_price else None
            
        return None
        
    except TimeoutException:
        st.warning(f"â³ Kol B'Yehuda: ×¤×¡×§ ×–××Ÿ ×¢×‘×•×¨ {query}.")
        return None
    except Exception as e:
        st.warning(f"âŒ ×©×’×™××ª Scraping ×‘-Kol B'Yehuda ×¢×‘×•×¨ {query}: {e}")
        return None


# ××™×¤×•×™ ×¤×•× ×§×¦×™×•×ª ×”-Scraping
SCRAPING_FUNCTIONS = {
    "KSP": search_and_scrape_ksp,
    "Kol_B_Yehuda": search_and_scrape_kolboyehuda
}

# --- 4. ×œ×•×’×™×§×ª ×”×©×•×•××” ×•×”×××©×§ (× ×©××¨×• ×›××¢×˜ ×–×”×™×) ---

@st.cache_data(ttl=3600) # ×©××™×¨×ª ×”×ª×•×¦××•×ª ×‘××˜××•×Ÿ ×œ×©×¢×”
def run_price_analysis(inventory, competitors_map, brands_to_monitor, threshold):
    results = []

    products_to_check = {name: price for name, price in inventory.items() 
                         if any(brand.lower() in name.lower() for brand in brands_to_monitor)}

    status_message = st.empty()
    
    for i, (product_name, my_price) in enumerate(products_to_check.items()):
        status_message.text(f"××¢×‘×“ ××•×¦×¨ {i+1}/{len(products_to_check)}: {product_name}...")
        
        row = {"×©× ×”×‘×•×©×": product_name, "×”××—×™×¨ ×©×œ×š": my_price}
        is_alert = False
        
        for comp_name, scraper_func in SCRAPING_FUNCTIONS.items():
            comp_price = scraper_func(product_name)
            
            row[f"××—×™×¨ {comp_name}"] = comp_price if comp_price else "×œ× × ××¦×"

            if comp_price:
                price_gap = (comp_price - my_price) / my_price
                row[f"×¤×¢×¨ {comp_name} (%)"] = round(price_gap * 100, 2)
                
                if abs(price_gap) >= threshold:
                    if price_gap > 0:
                        row["×”×ª×¨××”"] = f"×™×§×¨ ×‘-{round(price_gap * 100)}% ×-{comp_name}"
                        is_alert = True
                    else:
                        row["×”×ª×¨××”"] = f"×–×•×œ ×‘-{round(abs(price_gap) * 100)}% ×-{comp_name}"
                        is_alert = True
                
            else:
                row[f"×¤×¢×¨ {comp_name} (%)"] = "××™×Ÿ × ×ª×•×Ÿ"
        
        if not is_alert:
            row["×”×ª×¨××”"] = "×‘×˜×•×•×—"
            
        results.append(row)
        time.sleep(2) # ×”××ª× ×” ××¨×•×›×” ×™×•×ª×¨ ×›×“×™ ×œ×× ×•×¢ ×—×¡×™××” × ×•×¡×¤×ª

    status_message.text("âœ… ×¡×™×•× ×”× ×™×ª×•×—.")
    return pd.DataFrame(results)

# --- 5. ×××©×§ Streamlit ---

st.set_page_config(page_title="ğŸ’¸ PriceScout: × ×™×ª×•×— ×¤×¢×¨ ××—×™×¨×™ ×‘×©××™×", layout="wide")

st.title("ğŸ’¸ PriceScout: × ×™×ª×•×— ×¤×¢×¨ ××—×™×¨×™ ×‘×©××™×")
st.markdown("×›×œ×™ ×–×” ×× ×˜×¨ ××ª ××—×™×¨×™ ×”×‘×©××™× ×©×œ×š ××•×œ ××ª×—×¨×™× ×•×××ª×¨ ×¤×¢×¨×™× ××©××¢×•×ª×™×™×.")

# ×”×’×“×¨×•×ª ××©×ª××©
with st.sidebar:
    st.header("×”×’×“×¨×•×ª × ×™×ª×•×—")
    
    alert_threshold_percent = st.slider(
        "×¡×£ ×”×ª×¨××” (%)",
        min_value=5, max_value=50, value=int(PRICE_GAP_THRESHOLD * 100), step=1,
        help="×× ×¤×¢×¨ ×”××—×™×¨ ×œ××¢×œ×” ××• ×œ××˜×” ×¢×•×‘×¨ ×¡×£ ×–×”, ×ª×§×‘×œ ×”×ª×¨××”."
    )
    
    brands_input = st.text_area(
        "××•×ª×’×™× ×œ× ×™×˜×•×¨ (××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×)",
        ", ".join(BRANDS_TO_MONITOR)
    )
    
    current_threshold = alert_threshold_percent / 100.0
    current_brands = [b.strip() for b in brands_input.split(',') if b.strip()]

    st.info(f"×× ×˜×¨ ×›×¢×ª: {', '.join(current_brands)}. × ×ª×•× ×™× × ×©×œ×¤×™× ×‘×××¦×¢×•×ª Selenium.")

# ×›×¤×ª×•×¨ ×”×¤×¢×œ×”
if st.button("ğŸ”„ ×”×¤×¢×œ × ×™×ª×•×— ××—×™×¨×™×"):
    if not current_brands:
        st.error("×× × ×”×–×Ÿ ×œ×¤×—×•×ª ××•×ª×’ ××—×“ ×œ× ×™×˜×•×¨.")
    else:
        # × ×™×§×•×™ ×”××˜××•×Ÿ ×©×œ ×”× ×ª×•× ×™× ×›×“×™ ×œ×”×¤×¢×™×œ ×¡×¨×™×§×” ×—×“×©×”
        st.cache_data.clear() 
        
        with st.spinner('××‘×¦×¢ Web Scraping ×•××•×¡×£ × ×ª×•× ×™×... (×–×” ×™×›×•×œ ×œ×§×—×ª ×–××Ÿ)'):
            df_results = run_price_analysis(
                MY_INVENTORY, 
                COMPETITORS, 
                current_brands, 
                current_threshold
            )
            
            st.success("× ×™×ª×•×— ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
            
            st.session_state['df_results'] = df_results
            st.session_state['current_threshold'] = current_threshold

# ×”×¦×’×ª ×”×ª×•×¦××•×ª ×œ××—×¨ ×”×¨×™×¦×”
if 'df_results' in st.session_state:
    df_results = st.session_state['df_results']
    current_threshold = st.session_state['current_threshold']
    
    st.header("ğŸ’¡ ×¡×™×›×•× ×›×œ×œ×™")
    st.dataframe(df_results, use_container_width=True)
    
    df_alerts = df_results[df_results['×”×ª×¨××”'] != "×‘×˜×•×•×—"]
    
    st.header("ğŸš¨ ×”×ª×¨××•×ª ×¤×¢×¨ ××—×™×¨ ××©××¢×•×ª×™")
    
    if not df_alerts.empty:
        st.warning(f"× ××¦××• {len(df_alerts)} ×”×ª×¨××•×ª ×©×—×¦×• ××ª ×¡×£ ×”-{int(current_threshold*100)}%:")
        
        def highlight_alerts(row):
            style = [''] * len(row)
            if row['×”×ª×¨××”'].startswith('×™×§×¨'):
                style = ['background-color: #ffcccc'] * len(row) 
            elif row['×”×ª×¨××”'].startswith('×–×•×œ'):
                style = ['background-color: #ccffcc'] * len(row)
            return style

        st.dataframe(
            df_alerts.style.apply(highlight_alerts, axis=1),
            use_container_width=True
        )
    else:
        st.success("×›×œ ×”××—×™×¨×™× ×‘×˜×•×•×— ×”×ª×—×¨×•×ª×™! ××™×Ÿ ×”×ª×¨××•×ª ×—×“×©×•×ª.")

st.markdown("---")
st.caption("×©×™× ×œ×‘: Scraping ××ª×§×“× ×›×¨×•×š ×‘×¡×™×›×•×Ÿ ×—×¡×™××”. ×× × ×ª×§×œ×ª ×©×•×‘ ×‘×©×’×™××•×ª, ×™×™×ª×›×Ÿ ×©-KSP ×—×¡× ××ª ×”×©×¨×ª/×”×¨×©×ª ×©×œ×š.")
